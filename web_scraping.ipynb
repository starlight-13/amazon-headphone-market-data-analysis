{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting scraping process. Target: 150 pages\n",
      "Expected products: ~4050 products\n",
      "Estimated time: 2-3 hours\n",
      "Scraping page 1/150 (0.7% complete)\n",
      "Found 27 products on page 1\n",
      "Scraping page 2/150 (1.3% complete)\n",
      "Found 27 products on page 2\n",
      "Scraping page 3/150 (2.0% complete)\n",
      "Found 27 products on page 3\n",
      "Scraping page 4/150 (2.7% complete)\n",
      "Found 27 products on page 4\n",
      "Scraping page 5/150 (3.3% complete)\n",
      "Found 27 products on page 5\n",
      "Scraping page 6/150 (4.0% complete)\n",
      "Found 27 products on page 6\n",
      "Scraping page 7/150 (4.7% complete)\n",
      "Found 27 products on page 7\n",
      "Scraping page 8/150 (5.3% complete)\n",
      "Found 27 products on page 8\n",
      "Scraping page 9/150 (6.0% complete)\n",
      "Found 27 products on page 9\n",
      "Scraping page 10/150 (6.7% complete)\n",
      "Found 27 products on page 10\n",
      "Progress Update: 10 pages completed, 270 products scraped\n",
      "Scraping page 11/150 (7.3% complete)\n",
      "Found 27 products on page 11\n",
      "Scraping page 12/150 (8.0% complete)\n",
      "Found 27 products on page 12\n",
      "Scraping page 13/150 (8.7% complete)\n",
      "Found 27 products on page 13\n",
      "Scraping page 14/150 (9.3% complete)\n",
      "Found 27 products on page 14\n",
      "Scraping page 15/150 (10.0% complete)\n",
      "Found 27 products on page 15\n",
      "Scraping page 16/150 (10.7% complete)\n",
      "Found 27 products on page 16\n",
      "Scraping page 17/150 (11.3% complete)\n",
      "Found 27 products on page 17\n",
      "Scraping page 18/150 (12.0% complete)\n",
      "Found 27 products on page 18\n",
      "Scraping page 19/150 (12.7% complete)\n",
      "Found 27 products on page 19\n",
      "Scraping page 20/150 (13.3% complete)\n",
      "Found 27 products on page 20\n",
      "Progress Update: 20 pages completed, 540 products scraped\n",
      "Scraping page 21/150 (14.0% complete)\n",
      "Found 27 products on page 21\n",
      "Scraping page 22/150 (14.7% complete)\n",
      "Found 27 products on page 22\n",
      "Scraping page 23/150 (15.3% complete)\n",
      "Found 27 products on page 23\n",
      "Scraping page 24/150 (16.0% complete)\n",
      "Found 27 products on page 24\n",
      "Scraping page 25/150 (16.7% complete)\n",
      "Found 27 products on page 25\n",
      "Scraping page 26/150 (17.3% complete)\n",
      "Found 27 products on page 26\n",
      "Scraping page 27/150 (18.0% complete)\n",
      "Found 27 products on page 27\n",
      "Scraping page 28/150 (18.7% complete)\n",
      "Found 27 products on page 28\n",
      "Scraping page 29/150 (19.3% complete)\n",
      "Found 27 products on page 29\n",
      "Scraping page 30/150 (20.0% complete)\n",
      "Found 27 products on page 30\n",
      "Progress Update: 30 pages completed, 810 products scraped\n",
      "Scraping page 31/150 (20.7% complete)\n",
      "Found 27 products on page 31\n",
      "Scraping page 32/150 (21.3% complete)\n",
      "Products not found on page, breaking...\n",
      "\n",
      "=== SCRAPING COMPLETE ===\n",
      "Pages scraped: 32\n",
      "Total products: 837\n",
      "Final file saved: amazon_electronics_final_20250527_183753.csv\n",
      "\n",
      "Data summary:\n",
      "- Titles found: 837\n",
      "- Prices found: 835\n",
      "- MRPs found: 828\n",
      "- Discounts found: 828\n",
      "- Ratings found: 827\n",
      "- URLs found: 837\n",
      "- Delivery info found: 836\n",
      "- Availability found: 837\n",
      "\n",
      "First 5 entries:\n",
      "  1: Price=₹1,599, MRP=₹2,299, Delivery=FREE delivery, Availability=In stock\n",
      "  2: Price=₹340, MRP=₹999, Delivery=FREE delivery, Availability=In stock\n",
      "  3: Price=₹1,799, MRP=₹2,299, Delivery=FREE delivery, Availability=In stock\n",
      "  4: Price=₹1,099, MRP=₹4,489, Delivery=FREE delivery, Availability=In stock\n",
      "  5: Price=₹1,169, MRP=₹3,990, Delivery=FREE delivery, Availability=In stock\n"
     ]
    }
   ],
   "source": [
    "# Required imports\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException, StaleElementReferenceException\n",
    "import time\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Enhanced Chrome options for better bot detection avoidance\n",
    "options = Options()\n",
    "options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "options.add_argument(\"--disable-dev-shm-usage\")\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "options.add_argument(\"--disable-extensions\")\n",
    "options.add_argument(\"--disable-plugins\")\n",
    "options.add_argument(\"--disable-images\")\n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "options.add_experimental_option('useAutomationExtension', False)\n",
    "options.add_argument(\"<add your user agent here>\")\n",
    "\n",
    "driver = webdriver.Chrome(options=options)\n",
    "driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
    "\n",
    "# Initialize data storage\n",
    "titles, prices, mrps, discounts, ratings, review_counts = [], [], [], [], [], []\n",
    "brands, urls, asin_list, prime_flags, deliveries, availabilities = [], [], [], [], [], []\n",
    "\n",
    "def extract_product_data(product_element):\n",
    "    \"\"\"Extract all data from a single product element with CORRECT selectors based on HTML\"\"\"\n",
    "    try:\n",
    "        # Title - Working correctly\n",
    "        title = None\n",
    "        try:\n",
    "            title = product_element.find_element(By.CSS_SELECTOR, \"h2 a span\").text.strip()\n",
    "        except:\n",
    "            try:\n",
    "                title = product_element.find_element(By.CSS_SELECTOR, \"h2 span\").text.strip()\n",
    "            except:\n",
    "                title = None\n",
    "        \n",
    "        # Price - Working correctly\n",
    "        price = None\n",
    "        try:\n",
    "            price_element = product_element.find_element(By.CSS_SELECTOR, '.a-price')\n",
    "            price_text = price_element.text.strip()\n",
    "            if price_text:\n",
    "                price = price_text.split('\\n')[0].strip()\n",
    "        except:\n",
    "            try:\n",
    "                price_container = product_element.find_element(By.CSS_SELECTOR, '[data-cy=\"price-recipe\"]')\n",
    "                price_element = price_container.find_element(By.CSS_SELECTOR, '.a-price')\n",
    "                price_text = price_element.text.strip()\n",
    "                if price_text:\n",
    "                    price = price_text.split('\\n')[0].strip()\n",
    "            except:\n",
    "                price = None\n",
    "        \n",
    "        # MRP - Working correctly\n",
    "        mrp = None\n",
    "        try:\n",
    "            price_container = product_element.find_element(By.CSS_SELECTOR, '[data-cy=\"price-recipe\"]')\n",
    "            container_text = price_container.text\n",
    "            \n",
    "            lines = container_text.split('\\n')\n",
    "            for i, line in enumerate(lines):\n",
    "                if \"M.R.P:\" in line or \"MRP:\" in line:\n",
    "                    mrp_line = line.replace(\"M.R.P:\", \"\").replace(\"MRP:\", \"\").strip()\n",
    "                    if mrp_line and '₹' in mrp_line:\n",
    "                        mrp = mrp_line.split('(')[0].strip()\n",
    "                        break\n",
    "                    elif i + 1 < len(lines) and '₹' in lines[i + 1]:\n",
    "                        mrp = lines[i + 1].split('(')[0].strip()\n",
    "                        break\n",
    "        except:\n",
    "            try:\n",
    "                mrp_element = product_element.find_element(By.CSS_SELECTOR, '.a-price.a-text-price .a-offscreen')\n",
    "                mrp = mrp_element.text.strip()\n",
    "            except:\n",
    "                try:\n",
    "                    mrp_element = product_element.find_element(By.CSS_SELECTOR, '[data-a-strike=\"true\"] .a-offscreen')\n",
    "                    mrp = mrp_element.text.strip()\n",
    "                except:\n",
    "                    mrp = None\n",
    "        \n",
    "        # Discount - Working correctly\n",
    "        discount = None\n",
    "        try:\n",
    "            price_container = product_element.find_element(By.CSS_SELECTOR, '[data-cy=\"price-recipe\"]')\n",
    "            container_text = price_container.text\n",
    "            lines = container_text.split('\\n')\n",
    "            for line in lines:\n",
    "                if \"%\" in line and (\"off\" in line.lower() or \"discount\" in line.lower()):\n",
    "                    discount = line.strip()\n",
    "                    break\n",
    "        except:\n",
    "            try:\n",
    "                discount = product_element.find_element(By.XPATH, \".//span[contains(text(), '%') and contains(text(), 'off')]\").text.strip()\n",
    "            except:\n",
    "                discount = None\n",
    "        \n",
    "        # Rating - Working correctly\n",
    "        rating = None\n",
    "        try:\n",
    "            rating_elem = product_element.find_element(By.CSS_SELECTOR, \"[aria-label*='out of 5 stars']\")\n",
    "            rating = rating_elem.get_attribute('aria-label')\n",
    "        except:\n",
    "            try:\n",
    "                rating = product_element.find_element(By.CSS_SELECTOR, \"span.a-icon-alt\").text.strip()\n",
    "            except:\n",
    "                try:\n",
    "                    rating = product_element.find_element(By.XPATH, \".//span[contains(@aria-label, 'out of')]\").get_attribute('aria-label')\n",
    "                except:\n",
    "                    rating = None\n",
    "        \n",
    "        # Review count - Working correctly\n",
    "        reviews = None\n",
    "        try:\n",
    "            reviews = product_element.find_element(By.CSS_SELECTOR, \"a[href*='#customerReviews'] span\").text.strip()\n",
    "        except:\n",
    "            try:\n",
    "                reviews = product_element.find_element(By.XPATH, \".//a[contains(@href, 'customerReviews')]//span\").text.strip()\n",
    "            except:\n",
    "                try:\n",
    "                    reviews = product_element.find_element(By.XPATH, \".//span[contains(text(), ',') and (contains(text(), 'rating') or contains(text(), 'review'))]\").text.strip()\n",
    "                except:\n",
    "                    reviews = None\n",
    "        \n",
    "        # URL - FIXED extraction with multiple fallback strategies\n",
    "        url = None\n",
    "        try:\n",
    "            # Strategy 1: h2 a (most common)\n",
    "            url_element = product_element.find_element(By.CSS_SELECTOR, \"h2 a\")\n",
    "            url = url_element.get_attribute(\"href\")\n",
    "        except:\n",
    "            try:\n",
    "                # Strategy 2: Any link with data-cy title-recipe\n",
    "                url_element = product_element.find_element(By.CSS_SELECTOR, \"[data-cy='title-recipe'] a\")\n",
    "                url = url_element.get_attribute(\"href\")\n",
    "            except:\n",
    "                try:\n",
    "                    # Strategy 3: Any link containing product URL pattern\n",
    "                    url_element = product_element.find_element(By.CSS_SELECTOR, \"a[href*='/dp/']\")\n",
    "                    url = url_element.get_attribute(\"href\")\n",
    "                except:\n",
    "                    try:\n",
    "                        # Strategy 4: Any link in the product container\n",
    "                        url_element = product_element.find_element(By.CSS_SELECTOR, \"a\")\n",
    "                        potential_url = url_element.get_attribute(\"href\")\n",
    "                        if potential_url and ('/dp/' in potential_url or '/gp/' in potential_url):\n",
    "                            url = potential_url\n",
    "                    except:\n",
    "                        url = None\n",
    "        \n",
    "        # Ensure URL is complete\n",
    "        if url and not url.startswith(\"http\"):\n",
    "            url = \"https://www.amazon.in\" + url\n",
    "        \n",
    "        # ASIN\n",
    "        asin = product_element.get_attribute(\"data-asin\")\n",
    "        \n",
    "        # Prime - Working correctly\n",
    "        prime = False\n",
    "        try:\n",
    "            product_element.find_element(By.CSS_SELECTOR, \".a-icon-prime, [aria-label*='Prime']\")\n",
    "            prime = True\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Delivery info - UPDATED based on HTML structure\n",
    "        delivery = None\n",
    "        try:\n",
    "            # Based on HTML: Look for delivery text patterns\n",
    "            delivery = product_element.find_element(By.XPATH, \".//span[contains(text(), 'Get it by') or contains(text(), 'FREE delivery') or contains(text(), 'delivery')]\").text.strip()\n",
    "        except:\n",
    "            try:\n",
    "                # Alternative: Look for specific delivery containers\n",
    "                delivery = product_element.find_element(By.CSS_SELECTOR, \"[data-cy='delivery-recipe'] span\").text.strip()\n",
    "            except:\n",
    "                try:\n",
    "                    # Look for shipping/delivery related text\n",
    "                    delivery = product_element.find_element(By.XPATH, \".//span[contains(text(), 'Tomorrow') or contains(text(), 'Today') or contains(text(), 'Ships')]\").text.strip()\n",
    "                except:\n",
    "                    try:\n",
    "                        # Look in any span that mentions delivery timing\n",
    "                        delivery = product_element.find_element(By.XPATH, \".//span[contains(text(), 'delivery') or contains(text(), 'Delivery')]\").text.strip()\n",
    "                    except:\n",
    "                        delivery = None\n",
    "        \n",
    "        # Availability - UPDATED based on HTML structure  \n",
    "        availability = None\n",
    "        try:\n",
    "            # Look for stock status indicators\n",
    "            availability = product_element.find_element(By.XPATH, \".//span[contains(text(), 'In stock') or contains(text(), 'left in stock') or contains(text(), 'Only ') or contains(text(), 'Available')]\").text.strip()\n",
    "        except:\n",
    "            try:\n",
    "                # Look for shipping timeframes as availability indicators\n",
    "                availability = product_element.find_element(By.XPATH, \".//span[contains(text(), 'Ships in') or contains(text(), 'Usually ships') or contains(text(), 'Temporarily out')]\").text.strip()\n",
    "            except:\n",
    "                try:\n",
    "                    # Look for availability containers\n",
    "                    availability = product_element.find_element(By.CSS_SELECTOR, \"[data-cy='availability-recipe'] span\").text.strip()\n",
    "                except:\n",
    "                    try:\n",
    "                        # Look for any availability-related text\n",
    "                        availability = product_element.find_element(By.XPATH, \".//span[contains(text(), 'stock') or contains(text(), 'available') or contains(text(), 'unavailable')]\").text.strip()\n",
    "                    except:\n",
    "                        # If no specific availability found, check if product has price (indicates it's available)\n",
    "                        if price:\n",
    "                            availability = \"In stock\"\n",
    "                        else:\n",
    "                            availability = None\n",
    "        \n",
    "        # Brand from title - Working correctly\n",
    "        brand = None\n",
    "        if title:\n",
    "            brand = title.split()[0] if title.split() else None\n",
    "        \n",
    "        return {\n",
    "            'title': title,\n",
    "            'price': price,\n",
    "            'mrp': mrp,\n",
    "            'discount': discount,\n",
    "            'rating': rating,\n",
    "            'reviews': reviews,\n",
    "            'brand': brand,\n",
    "            'url': url,\n",
    "            'asin': asin,\n",
    "            'prime': prime,\n",
    "            'delivery': delivery,\n",
    "            'availability': availability\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting product data: {e}\")\n",
    "        return None\n",
    "\n",
    "# Start scraping\n",
    "base_url = \"https://www.amazon.in/s?i=electronics&rh=n%3A1388921031&s=popularity-rank&fs=true\"\n",
    "driver.get(base_url)\n",
    "time.sleep(random.uniform(3, 5))\n",
    "\n",
    "page_count = 0\n",
    "max_pages = 150  # Target 150 pages for ~4,000 products\n",
    "\n",
    "print(f\"Starting scraping process. Target: {max_pages} pages\")\n",
    "print(f\"Expected products: ~{max_pages * 27} products\")\n",
    "print(f\"Estimated time: 2-3 hours\")\n",
    "\n",
    "while page_count < max_pages:\n",
    "    page_count += 1\n",
    "    print(f\"Scraping page {page_count}/{max_pages} ({(page_count/max_pages)*100:.1f}% complete)\")\n",
    "    \n",
    "    # Wait for products to load\n",
    "    try:\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.XPATH, '//div[@data-component-type=\"s-search-result\"]'))\n",
    "        )\n",
    "    except TimeoutException:\n",
    "        print(\"Products not found on page, breaking...\")\n",
    "        break\n",
    "    \n",
    "    # Random delay\n",
    "    time.sleep(random.uniform(2, 4))\n",
    "    \n",
    "    # Find all products on current page\n",
    "    products = driver.find_elements(By.XPATH, '//div[@data-component-type=\"s-search-result\"]')\n",
    "    print(f\"Found {len(products)} products on page {page_count}\")\n",
    "    \n",
    "    for i, product in enumerate(products):\n",
    "        try:\n",
    "            # Re-find elements to avoid stale reference\n",
    "            products_fresh = driver.find_elements(By.XPATH, '//div[@data-component-type=\"s-search-result\"]')\n",
    "            if i < len(products_fresh):\n",
    "                product_data = extract_product_data(products_fresh[i])\n",
    "                \n",
    "                if product_data:\n",
    "                    titles.append(product_data['title'])\n",
    "                    prices.append(product_data['price'])\n",
    "                    mrps.append(product_data['mrp'])\n",
    "                    discounts.append(product_data['discount'])\n",
    "                    ratings.append(product_data['rating'])\n",
    "                    review_counts.append(product_data['reviews'])\n",
    "                    brands.append(product_data['brand'])\n",
    "                    urls.append(product_data['url'])\n",
    "                    asin_list.append(product_data['asin'])\n",
    "                    prime_flags.append(product_data['prime'])\n",
    "                    deliveries.append(product_data['delivery'])\n",
    "                    availabilities.append(product_data['availability'])\n",
    "        \n",
    "        except StaleElementReferenceException:\n",
    "            print(f\"Stale element on product {i}, skipping...\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing product {i}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Progress update every 10 pages\n",
    "    if page_count % 10 == 0:\n",
    "        current_products = len(titles)\n",
    "        print(f\"Progress Update: {page_count} pages completed, {current_products} products scraped\")\n",
    "        \n",
    "        # Save intermediate results every 25 pages\n",
    "        if page_count % 25 == 0:\n",
    "            temp_df = pd.DataFrame({\n",
    "                \"Title\": titles,\n",
    "                \"Brand\": brands,\n",
    "                \"Price\": prices,\n",
    "                \"MRP\": mrps,\n",
    "                \"Discount\": discounts,\n",
    "                \"Rating\": ratings,\n",
    "                \"Review Count\": review_counts,\n",
    "                \"Prime\": prime_flags,\n",
    "                \"Delivery Info\": deliveries,\n",
    "                \"Availability\": availabilities,\n",
    "                \"ASIN\": asin_list,\n",
    "                \"URL\": urls\n",
    "            })\n",
    "            \n",
    "            import datetime\n",
    "            timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            temp_filename = f\"amazon_electronics_backup_{page_count}pages_{timestamp}.csv\"\n",
    "            temp_df.to_csv(temp_filename, index=False)\n",
    "            print(f\"Backup saved: {temp_filename}\")\n",
    "    \n",
    "    # Try to go to next page\n",
    "    try:\n",
    "        next_button = WebDriverWait(driver, 5).until(\n",
    "            EC.element_to_be_clickable((By.CSS_SELECTOR, \"a.s-pagination-next, a[aria-label='Go to next page']\"))\n",
    "        )\n",
    "        \n",
    "        driver.execute_script(\"arguments[0].scrollIntoView(true);\", next_button)\n",
    "        time.sleep(1)\n",
    "        next_button.click()\n",
    "        time.sleep(random.uniform(3, 5))\n",
    "        \n",
    "    except (TimeoutException, NoSuchElementException):\n",
    "        print(\"No more pages found.\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"Error navigating to next page: {e}\")\n",
    "        break\n",
    "\n",
    "# Create final DataFrame and save\n",
    "df = pd.DataFrame({\n",
    "    \"Title\": titles,\n",
    "    \"Brand\": brands,\n",
    "    \"Price\": prices,\n",
    "    \"MRP\": mrps,\n",
    "    \"Discount\": discounts,\n",
    "    \"Rating\": ratings,\n",
    "    \"Review Count\": review_counts,\n",
    "    \"Prime\": prime_flags,\n",
    "    \"Delivery Info\": deliveries,\n",
    "    \"Availability\": availabilities,\n",
    "    \"ASIN\": asin_list,\n",
    "    \"URL\": urls\n",
    "})\n",
    "\n",
    "# Save with timestamp\n",
    "import datetime\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "filename = f\"amazon_electronics_final_{timestamp}.csv\"\n",
    "df.to_csv(filename, index=False)\n",
    "\n",
    "print(f\"\\n=== SCRAPING COMPLETE ===\")\n",
    "print(f\"Pages scraped: {page_count}\")\n",
    "print(f\"Total products: {len(df)}\")\n",
    "print(f\"Final file saved: {filename}\")\n",
    "print(f\"\\nData summary:\")\n",
    "print(f\"- Titles found: {sum(1 for x in titles if x)}\")\n",
    "print(f\"- Prices found: {sum(1 for x in prices if x)}\")\n",
    "print(f\"- MRPs found: {sum(1 for x in mrps if x)}\")\n",
    "print(f\"- Discounts found: {sum(1 for x in discounts if x)}\")\n",
    "print(f\"- Ratings found: {sum(1 for x in ratings if x)}\")\n",
    "print(f\"- URLs found: {sum(1 for x in urls if x)}\")\n",
    "print(f\"- Delivery info found: {sum(1 for x in deliveries if x)}\")\n",
    "print(f\"- Availability found: {sum(1 for x in availabilities if x)}\")\n",
    "\n",
    "# Show first few entries for debugging\n",
    "print(f\"\\nFirst 5 entries:\")\n",
    "for i in range(min(5, len(titles))):\n",
    "    print(f\"  {i+1}: Price={prices[i]}, MRP={mrps[i]}, Delivery={deliveries[i]}, Availability={availabilities[i]}\")\n",
    "\n",
    "# Close driver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
